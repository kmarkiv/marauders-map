<!DOCTYPE html>
<head>
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
    <title>Hello, AR Cube!</title>
    <!-- include three.js library -->
    <script src='build/three.min.js'></script>
    <!-- include jsartookit -->
    <script src="jsartoolkit5/artoolkit.min.js"></script>
    <script src="jsartoolkit5/artoolkit.api.js"></script>
    <!-- include threex.artoolkit -->
    <script src="threex/threex-artoolkitsource.js"></script>
    <script src="threex/threex-artoolkitcontext.js"></script>
    <script src="threex/threex-arbasecontrols.js"></script>
    <script src="threex/threex-armarkercontrols.js"></script>
    <script src="threex/threex-arsmoothedcontrols.js"></script>
</head>

<body style='margin : 0px; overflow: hidden; font-family: Monospace;'>

<video autoplay muted="muted" loop id="myVideo" style="visibility: hidden">
    <source src="images/drone.mp4" type="video/mp4">
</video>


<!--
  Example created by Lee Stemkoski: https://github.com/stemkoski
  Based on the AR.js library and examples created by Jerome Etienne: https://github.com/jeromeetienne/AR.js/
-->

<script>

    var scene, camera, renderer, clock, deltaTime, totalTime;

    var arToolkitSource, arToolkitContext, smoothedControls;

    var markerRoot1, markerRoot2, listener, materialTextured;
    var sound;
    var mesh1, videoImage, videoImageContext;
    var count = 0;
    var updateFcts	= [];


    var video = document.getElementById('myVideo');

    var videoTexture = new THREE.VideoTexture(video);

    videoTexture.minFilter = THREE.LinearFilter;
    videoTexture.magFilter = THREE.LinearFilter;

    var canPlayMp4	= document.createElement('video').canPlayType('video/mp4') !== '' ? true : false
	var canPlayOgg	= document.createElement('video').canPlayType('video/ogg') !== '' ? true : false
	if( canPlayMp4 ){
		console.log("play video")
	}
	if( canPlayOgg ){
		console.log("play audio")
	}else	alert('cant play mp4 or ogv');


	updateFcts.push(function(delta, now){
		videoTexture.update(delta, now)
	})




    initialize();
    animate();

    function initialize() {
        scene = new THREE.Scene();


        let ambientLight = new THREE.AmbientLight(0xcccccc, 0.5);
        scene.add(ambientLight);

        camera = new THREE.Camera();

        listener = new THREE.AudioListener();
        camera.add(listener);

        // create the PositionalAudio object (passing in the listener)
        //
        sound = new THREE.PositionalAudio(listener);

        scene.add(camera);

        renderer = new THREE.WebGLRenderer({
            antialias: true,
            alpha: true
        });
        renderer.setClearColor(new THREE.Color('lightgrey'), 0)
        renderer.setSize(640, 480);
        renderer.domElement.style.position = 'absolute'
        renderer.domElement.style.top = '0px'
        renderer.domElement.style.left = '0px'
        document.body.appendChild(renderer.domElement);

        clock = new THREE.Clock();
        deltaTime = 0;
        totalTime = 0;

        ////////////////////////////////////////////////////////////
        // setup arToolkitSource
        ////////////////////////////////////////////////////////////

        arToolkitSource = new THREEx.ArToolkitSource({
            sourceType: 'webcam',
        });

        function onResize() {
            arToolkitSource.onResize()
            arToolkitSource.copySizeTo(renderer.domElement)
            if (arToolkitContext.arController !== null) {
                arToolkitSource.copySizeTo(arToolkitContext.arController.canvas)
            }
        }

        arToolkitSource.init(function onReady() {
            onResize()
        });

        // handle resize event
        window.addEventListener('resize', function () {
            onResize()
        });

        ////////////////////////////////////////////////////////////
        // setup arToolkitContext
        ////////////////////////////////////////////////////////////

        // create atToolkitContext
        arToolkitContext = new THREEx.ArToolkitContext({
            cameraParametersUrl: 'data/camera_para.dat',
            detectionMode: 'mono'
        });

        // copy projection matrix to camera when initialization complete
        arToolkitContext.init(function onCompleted() {
            camera.projectionMatrix.copy(arToolkitContext.getProjectionMatrix());
        });


        ////////////////////////////////////////////////////////////
        // setup markerRoots
        ////////////////////////////////////////////////////////////

        // build markerControls
        markerRoot1 = new THREE.Group();
        scene.add(markerRoot1);

        let markerControls1 = new THREEx.ArMarkerControls(arToolkitContext, markerRoot1, {
            type: 'pattern',
            patternUrl: "data/patt.hiro",
        })

        // interpolates from last position to create smoother transitions when moving.
        // parameter lerp values near 0 are slow, near 1 are fast (instantaneous).
        let smoothedRoot = new THREE.Group();
        scene.add(smoothedRoot);
        smoothedControls = new THREEx.ArSmoothedControls(smoothedRoot, {
            lerpPosition: 0.8,
            lerpQuaternion: 0.8,
            lerpScale: 1,
            // minVisibleDelay: 1,
            // minUnvisibleDelay: 1,
        });


        var textureLoader = new THREE.TextureLoader().load(
            'images/drone-vector-animated-gif.gif'
        );

        let geometry1 = new THREE.PlaneGeometry(1, 1, 1);

        let materialTextured = new THREE.MeshBasicMaterial({
            map	: videoTexture,
             side: THREE.DoubleSide
        });

        const playPromise = video.play();
        if (playPromise !== null) {
            playPromise.catch(() => {
                video.play();
            })
        }


        mesh1 = new THREE.Mesh(geometry1, materialTextured);
        mesh1.position.y = 0.1;
        mesh1.rotation.x = -Math.PI / 2;

        // markerRoot1.add( mesh1 );
        smoothedRoot.add(sound);
        smoothedRoot.add(mesh1);
    }


    function update() {
        // update artoolkit on every frame
        if (arToolkitSource.ready !== false)
            arToolkitContext.update(arToolkitSource.domElement);

        // additional code for smoothed controls
        smoothedControls.update(markerRoot1);

        if (markerRoot1.visible === true) {
           // materialTextured.map.texture.needsUpdate = true;

            // materialTextured.map.needsUpdate = true;

            //mesh1.material.map.needsUpdate = true;

            //console.log(markerRoot1.getWorldPosition())
            if (sound.isPlaying === false) {
                 playDrone()
            }
            //play(markerRoot1.getWorldPosition().x);
        }
        else {

            //  if (sound.isPlaying === true)
            //  sound.pause();
            if (sound.isPlaying === true)
                stop();
        }

    }

    function playDrone() {

        count += 1;

        if (count % 30 == 0) {
            var audio = "drone";

            // load a sound and set it as the Audio object's buffer
            var audioLoader = new THREE.AudioLoader();
            audioLoader.load('sounds/' + audio + ".wav", function (buffer) {
                sound.setBuffer(buffer);
                sound.setLoop(false);
                sound.setVolume(1.0);
                sound.play();
            });
        }
    }

    function play(X) {

        count += 1;

        if (count % 30 == 0) {


            var audio = "steady";
            if (X < -0.8) {
                audio = "left"
            }
            else if (X < 0.2) {
                audio = "steady"
            }
            else {
                audio = "right"
            }


            sound = new THREE.Audio(listener);

            // load a sound and set it as the Audio object's buffer
            var audioLoader = new THREE.AudioLoader();
            audioLoader.load('sounds/' + audio + ".wav", function (buffer) {
                sound.setBuffer(buffer);
                sound.setLoop(false);
                sound.setVolume(0.5);
                sound.play();
            });
        }
    }

    function pause() {


    }


    function render() {
        renderer.render(scene, camera);
    }


    function animate() {
        requestAnimationFrame(animate);
        deltaTime = clock.getDelta();
        totalTime += deltaTime;
        update();
        render();
    }

</script>

</body>
</html>